<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Layer (ann.Ann__Perceptron_biases.Layer)</title><link rel="stylesheet" href="../../../odoc.css"/><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div class="content"><header><nav><a href="../index.html">Up</a> â€“ <a href="../../index.html">ann</a> &#x00BB; <a href="../index.html">Ann__Perceptron_biases</a> &#x00BB; Layer</nav><h1>Module <code>Ann__Perceptron_biases.Layer</code></h1></header><h3 class="heading">Parameters</h3><dl><code><a href="argument-1-D/index.html">D</a> : <a href="../../Ann/Differentiable/index.html#module-type-Sig">Ann.Differentiable.Sig</a></code></dl><h3 class="heading">Signature</h3><dl><dt class="spec type" id="type-t"><a href="#type-t" class="anchor"></a><code><span class="keyword">type </span>t</code></dt><dd><p>Type of a layer</p></dd></dl><dl><dt class="spec value" id="val-create_layer"><a href="#val-create_layer" class="anchor"></a><code><span class="keyword">val </span>create_layer : inputs:int <span>&#45;&gt;</span> outputs:int <span>&#45;&gt;</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>create_layer i o</code> creates a new layer that takes in <code>i</code> inputs and has <code>o</code> outputs.</p></dd></dl><dl><dt class="spec value" id="val-forward_propagate"><a href="#val-forward_propagate" class="anchor"></a><code><span class="keyword">val </span>forward_propagate : ?&#8288;dp:float <span>&#45;&gt;</span> <a href="../../Ann/Matrix/index.html#type-t">Ann.Matrix.t</a> <span>&#45;&gt;</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="../../Ann/Matrix/index.html#type-t">Ann.Matrix.t</a></code></dt><dd><p><code>forward_propogate d m l</code> is a matrix representing the output of the layer after being evaluated. The layer <code>l</code> is evaluated using data matrix <code>d</code> with a dropout percentage of <code>d</code>.</p></dd></dl><dl><dt class="spec value" id="val-apply_delta"><a href="#val-apply_delta" class="anchor"></a><code><span class="keyword">val </span>apply_delta : <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>apply_delta d l</code> applies the changes, deltas <code>d</code>, from back_propogation to the layer <code>l</code>.</p></dd></dl><dl><dt class="spec value" id="val-add_derivatives"><a href="#val-add_derivatives" class="anchor"></a><code><span class="keyword">val </span>add_derivatives : <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>add_derivatives d1 d2</code> is the derivative layer representing the sum of the two derivatives</p></dd></dl><dl><dt class="spec value" id="val-average_derivative"><a href="#val-average_derivative" class="anchor"></a><code><span class="keyword">val </span>average_derivative : <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> float <span>&#45;&gt;</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>average_derivative d n</code> is the average of the derivative <code>d</code> over <code>n</code> entries.</p></dd></dl><dl><dt class="spec value" id="val-backward_propagate"><a href="#val-backward_propagate" class="anchor"></a><code><span class="keyword">val </span>backward_propagate : learning_rate:float <span>&#45;&gt;</span> delta:<a href="../../Ann/Matrix/index.html#type-t">Ann.Matrix.t</a> <span>&#45;&gt;</span> layer:<a href="index.html#type-t">t</a> <span>&#45;&gt;</span> next_layer:<a href="index.html#type-t">t</a> option <span>&#45;&gt;</span> activation:<a href="../../Ann/Matrix/index.html#type-t">Ann.Matrix.t</a> <span>&#45;&gt;</span> <a href="../../Ann/Matrix/index.html#type-t">Ann.Matrix.t</a><span class="keyword"> * </span><a href="index.html#type-t">t</a></code></dt><dd><p><code>backward_propogate a d l n_l act</code> is the new layer with deltas that is the result of applying the backward_propogation algorithm using learning rate <code>a</code>, a delta <code>d</code> representing the differentiable function we are using, the current layer <code>l</code>, the next_layer <code>n_l</code> the was propogated before <code>l</code>, and the activation function <code>act</code>.</p></dd></dl><dl><dt class="spec value" id="val-format"><a href="#val-format" class="anchor"></a><code><span class="keyword">val </span>format : Format.formatter <span>&#45;&gt;</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> unit</code></dt><dd><p><code>format fmt l</code> prints out <code>l</code> to <code>fmt</code>.</p></dd></dl><dl><dt class="spec value" id="val-print"><a href="#val-print" class="anchor"></a><code><span class="keyword">val </span>print : <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> unit</code></dt><dd><p><code>print l</code> prints layer <code>l</code> to std out</p></dd></dl><dl><dt class="spec value" id="val-save"><a href="#val-save" class="anchor"></a><code><span class="keyword">val </span>save : string <span>&#45;&gt;</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> unit</code></dt><dd><p><code>save s l</code> saves the layer <code>l</code> to a file <code>s</code> within a network archive to be used again.</p></dd></dl><dl><dt class="spec value" id="val-load"><a href="#val-load" class="anchor"></a><code><span class="keyword">val </span>load : string <span>&#45;&gt;</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>load s</code> loads the selected file <code>s</code> from a network archive back into a layer.</p></dd></dl></div></body></html>